{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain Agent 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "\n",
    "tools = [TavilySearchResults(max_results = 1)]\n",
    "\n",
    "# 프롬프트 로드\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "\n",
    "# LLM 모델 정의\n",
    "llm = ChatOpenAI(model = \"gpt-4o-mini\", temperature = 0)\n",
    "\n",
    "# Agent 생성\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphState 정의\n",
    "\n",
    "1. **input**: 사용자의 입력\n",
    "2. **chat_hisotry**: 지난 대화 기록 메시지\n",
    "3. **intermediate_steps**: 매 스텝 에이전트의 행동과 관측 결과를 저장하는 리스트\n",
    "4. **agent_outcome**: 에이전트의 결과. AgentAction, AgentFinish 중 하나."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, List, Union\n",
    "from langchain_core.agents import AgentAction, AgentFinish\n",
    "from langchain_core.messages import BaseMessage\n",
    "import operator\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    input: str\n",
    "    chat_history: List[BaseMessage]\n",
    "    # agnet_outcome 변수가 초기에는 None 값을 가질 수 있어야 하므로, 타입 정의에 None을 유효한 타입으로 포함\n",
    "    agent_outcome: Union[AgentAction, AgentFinish, None]\n",
    "    # 새로운 값이 들어올 때 기존 값을 대체(overwrite)하는 것이 아니라 기존 리스트에 추가(append)되는 방식으로 동작\n",
    "    intermediate_steps: Annotated[list[tuple[AgentAction, str]], operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 노드(Node) 정의\n",
    "\n",
    "1. **Agent**: 어떤 행동을 취할지(있다면) 결정하는 역할을 담당합니다.\n",
    "2. **A function to invoke tool**: 에이전트가 사용하기 위해 호출한 함수. 각 노드에서 해당 액션 수행.\n",
    "\n",
    "1. **Conditional Edge**: 특정 조건을 만족하는 경우에만 특정 노드로 이동하는 역할을 담당\n",
    "2. **Normal Edge**: 도구 호출이 일어난 후, 항상 다음 노드로 이동하는 역할."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# 도구 실행 class\n",
    "# 도구 호출 후 결과를 반환하는 역할\n",
    "tool_executor = ToolNode(tools) \n",
    "\n",
    "# 에이전트 정의\n",
    "def run_agent(data):\n",
    "    agent_outcome = agent.invoke(data)\n",
    "    return {\"agent_outcome\": agent_outcome}\n",
    "\n",
    "# 도구 실행 함수 정의\n",
    "def execute_tool(data):\n",
    "    agent_action = data[\"agent_outcome\"]\n",
    "    output = tool_executor.invoke(agent_action)\n",
    "    return {\"intermediate_steps\": [(agent_action, str(output))]}\n",
    "\n",
    "# conditional edge 결정 logic 정의\n",
    "def should_continue(data):\n",
    "    if isinstance(data[\"agent_outcome\"], AgentFinish):\n",
    "        return 'end'\n",
    "    else:\n",
    "        return 'continue'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "# 새로운 그래프 정의\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# 노드 추가\n",
    "workflow.add_node(\"agent\", run_agent)\n",
    "workflow.add_node(\"action\", execute_tool)\n",
    "\n",
    "# 조건부 엣지 추가\n",
    "workflow.add_conditional_edges(\"agent\", should_continue, {\"continue\": \"action\", \"end\": END})\n",
    "\n",
    "# 일반 엣지 추가\n",
    "workflow.add_edge(\"action\", \"agent\")\n",
    "\n",
    "# 그래프 시작점 정의\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# 그래프 컴파일\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent_outcome': AgentActionMessageLog(tool='tavily_search_results_json', tool_input={'query': 'current weather in San Francisco'}, log=\"\\nInvoking: `tavily_search_results_json` with `{'query': 'current weather in San Francisco'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"query\":\"current weather in San Francisco\"}', 'name': 'tavily_search_results_json'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 91, 'total_tokens': 113, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f59a81427f', 'finish_reason': 'function_call', 'logprobs': None}, id='run-5607ffd8-f9fa-4979-830a-c5ab0499d31b-0', usage_metadata={'input_tokens': 91, 'output_tokens': 22, 'total_tokens': 113, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})])}\n",
      "---\n",
      "{'intermediate_steps': [(AgentActionMessageLog(tool='tavily_search_results_json', tool_input={'query': 'current weather in San Francisco'}, log=\"\\nInvoking: `tavily_search_results_json` with `{'query': 'current weather in San Francisco'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"query\":\"current weather in San Francisco\"}', 'name': 'tavily_search_results_json'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 91, 'total_tokens': 113, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f59a81427f', 'finish_reason': 'function_call', 'logprobs': None}, id='run-5607ffd8-f9fa-4979-830a-c5ab0499d31b-0', usage_metadata={'input_tokens': 91, 'output_tokens': 22, 'total_tokens': 113, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})]), \"{'messages': []}\")]}\n",
      "---\n",
      "{'agent_outcome': AgentFinish(return_values={'output': \"I couldn't retrieve the current weather information for San Francisco at the moment. However, you can check a reliable weather website or app for the latest updates. Would you like to know about the typical weather in San Francisco during this time of year?\"}, log=\"I couldn't retrieve the current weather information for San Francisco at the moment. However, you can check a reliable weather website or app for the latest updates. Would you like to know about the typical weather in San Francisco during this time of year?\")}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "input = {\"input\": \"What is the weather in sf\", \"chat_history\": []}\n",
    "for s in app.stream(input):\n",
    "    print(list(s.values())[0])\n",
    "    print('---')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wanted_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
